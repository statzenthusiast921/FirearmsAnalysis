{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Range of years\n",
    "years = np.arange(1991,2019).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to see if the website allows scraping\n",
    "url = 'https://fred.stlouisfed.org/release/tables?rid=118&eid=259194'\n",
    "page = requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>index</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>46</td>\n",
       "      <td>7475575</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>47</td>\n",
       "      <td>6178645</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>48</td>\n",
       "      <td>1816438</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>49</td>\n",
       "      <td>5514026</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>50</td>\n",
       "      <td>509106</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  index      Pop  Year\n",
       "46       Virginia     46  7475575  2004\n",
       "47     Washington     47  6178645  2004\n",
       "48  West Virginia     48  1816438  2004\n",
       "49      Wisconsin     49  5514026  2004\n",
       "50        Wyoming     50   509106  2004"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_str = '2004'\n",
    "full_link = url+'&od='+year_str+'-01-01#'\n",
    "page = requests.get(full_link)\n",
    "    \n",
    "#Grab the components - make the soup\n",
    "soup = BeautifulSoup(page.text,'lxml')\n",
    "\n",
    "\n",
    "#Grab the states and make a dataframe\n",
    "states = soup.find_all('span',class_='fred-rls-elm-nm')\n",
    "\n",
    "\n",
    "\n",
    "states_list = []\n",
    "for i in states:\n",
    "    state_name = i.text\n",
    "    states_list.append(state_name)\n",
    "\n",
    "states_df = pd.DataFrame(states_list,columns=['State'])\n",
    "states_df['index'] = np.arange(len(states_df))\n",
    "#states_df['Year'] = str(i)\n",
    "\n",
    "#Grab the population values and make a dataframe\n",
    "pops = soup.find_all('td',class_='fred-rls-elm-vl-td')\n",
    "\n",
    "\n",
    "pop_list = []\n",
    "for i in pops:\n",
    "    pop_num = i.text\n",
    "    pop_list.append(pop_num)\n",
    "\n",
    "\n",
    "\n",
    "pop_df = pd.DataFrame(pop_list,columns=['Pop'])\n",
    "\n",
    "pop_df['Pop'] = pop_df['Pop'].replace('\\n',\"\",regex=True).str.strip()\n",
    "pop_df['Pop'] = pop_df['Pop'].replace(',',\"\",regex=True)\n",
    "pop_df = pop_df.apply(pd.to_numeric,errors='ignore')\n",
    "pop_df = pop_df.iloc[::3, :]\n",
    "pop_df['Pop'] = (pop_df['Pop']*1000).astype(int)\n",
    "pop_df['index'] = np.arange(len(pop_df))\n",
    "#pop_df['Year'] = str(i)\n",
    "\n",
    "\n",
    "df = pd.merge(\n",
    "        states_df,\n",
    "        pop_df,\n",
    "        how='left',\n",
    "        on=['index']\n",
    ")\n",
    "    \n",
    "df['Year'] = year_str\n",
    "df.tail()\n",
    "\n",
    "#     for i in list_of_dfs\n",
    "#     full_df = pd.concat(list_of_dfs, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>index</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>4091025</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>1</td>\n",
       "      <td>569273</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>2</td>\n",
       "      <td>3762394</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "      <td>2370666</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>4</td>\n",
       "      <td>30414114</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>46</td>\n",
       "      <td>8510920</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>47</td>\n",
       "      <td>7526793</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>48</td>\n",
       "      <td>1805953</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>49</td>\n",
       "      <td>5809319</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>50</td>\n",
       "      <td>579054</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1428 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  index       Pop  Year\n",
       "0         Alabama      0   4091025  1991\n",
       "1          Alaska      1    569273  1991\n",
       "2         Arizona      2   3762394  1991\n",
       "3        Arkansas      3   2370666  1991\n",
       "4      California      4  30414114  1991\n",
       "..            ...    ...       ...   ...\n",
       "46       Virginia     46   8510920  2018\n",
       "47     Washington     47   7526793  2018\n",
       "48  West Virginia     48   1805953  2018\n",
       "49      Wisconsin     49   5809319  2018\n",
       "50        Wyoming     50    579054  2018\n",
       "\n",
       "[1428 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set up dataframe\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'State':[''], \n",
    "        'Year':[''],\n",
    "        'Population':['']\n",
    "    }\n",
    ")\n",
    "\n",
    "list_of_dfs=[]\n",
    "\n",
    "#For each year - run through this process\n",
    "for i in years:\n",
    "    full_link = url+'&od='+str(i)+'-01-01#'\n",
    "    page = requests.get(full_link)\n",
    "    soup = BeautifulSoup(page.text,'lxml')\n",
    "    \n",
    "    \n",
    "    #Grab the state names\n",
    "    states = soup.find_all('span',class_='fred-rls-elm-nm')\n",
    "    states_list = []\n",
    "    for j in states:\n",
    "        state_name = j.text\n",
    "        states_list.append(state_name)\n",
    "\n",
    "    #Package into df\n",
    "    states_df = pd.DataFrame(states_list,columns=['State'])\n",
    "    states_df['index'] = np.arange(len(states_df))\n",
    "    \n",
    "    \n",
    "    #Grab the population values\n",
    "    pops = soup.find_all('td',class_='fred-rls-elm-vl-td')\n",
    "    pop_list = []\n",
    "    for k in pops:\n",
    "        pop_num = k.text\n",
    "        pop_list.append(pop_num)\n",
    "\n",
    "\n",
    "    #Package into a df\n",
    "    pop_df = pd.DataFrame(pop_list,columns=['Pop'])\n",
    "    \n",
    "    #Clean up population values\n",
    "    pop_df['Pop'] = pop_df['Pop'].replace('\\n',\"\",regex=True).str.strip()\n",
    "    pop_df['Pop'] = pop_df['Pop'].replace(',',\"\",regex=True)\n",
    "    pop_df = pop_df.apply(pd.to_numeric,errors='ignore')\n",
    "    #Grab every third value\n",
    "    pop_df = pop_df.iloc[::3, :]\n",
    "    pop_df['Pop'] = (pop_df['Pop']*1000).astype(int)\n",
    "    \n",
    "    #Create index for joining\n",
    "    pop_df['index'] = np.arange(len(pop_df))\n",
    "    \n",
    "    #Combine dataframes\n",
    "    full_df = pd.merge(\n",
    "        states_df,\n",
    "        pop_df,\n",
    "        how='left',\n",
    "        on=['index']\n",
    "    )\n",
    "    year_pop = str(i)\n",
    "    full_df['Year'] = year_pop\n",
    "    \n",
    "    \n",
    "    list_of_dfs.append(full_df)\n",
    "    \n",
    "full_df = pd.concat(list_of_dfs)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_df.to_csv('states_and_pops.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
