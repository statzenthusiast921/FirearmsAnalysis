{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Range of years\n",
    "years = np.arange(2006,2019).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to see if the website allows scraping\n",
    "url = 'https://fred.stlouisfed.org/release/tables?rid=330&eid=391444'\n",
    "page = requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>index</th>\n",
       "      <th>Bach_Perc</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>46</td>\n",
       "      <td>32.7</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>47</td>\n",
       "      <td>30.5</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>48</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>49</td>\n",
       "      <td>25.1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>50</td>\n",
       "      <td>22.7</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  index Bach_Perc  Year\n",
       "46       Virginia     46      32.7  2006\n",
       "47     Washington     47      30.5  2006\n",
       "48  West Virginia     48      16.5  2006\n",
       "49      Wisconsin     49      25.1  2006\n",
       "50        Wyoming     50      22.7  2006"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_str = '2006'\n",
    "full_link = url+'&od='+year_str+'-01-01#'\n",
    "page = requests.get(full_link)\n",
    "\n",
    "\n",
    "#Grab the components - make the soup\n",
    "soup = BeautifulSoup(page.text,'lxml')\n",
    "\n",
    "\n",
    "# #Grab the states and make a dataframe\n",
    "states = soup.find_all('span',class_='fred-rls-elm-nm')\n",
    "\n",
    "\n",
    "\n",
    "states_list = []\n",
    "for i in states:\n",
    "    state_name = i.text\n",
    "    states_list.append(state_name)\n",
    "\n",
    "states_df = pd.DataFrame(states_list,columns=['State'])\n",
    "states_df['index'] = np.arange(len(states_df))\n",
    "states_df\n",
    "# #states_df['Year'] = str(i)\n",
    "\n",
    "#Grab the population values and make a dataframe\n",
    "bachs = soup.find_all('td',class_='fred-rls-elm-vl-td')\n",
    "\n",
    "\n",
    "bach_list = []\n",
    "for i in bachs:\n",
    "    bach_num = i.text\n",
    "    bach_list.append(bach_num)\n",
    "\n",
    "\n",
    "\n",
    "bach_df = pd.DataFrame(bach_list,columns=['Bach_Perc'])\n",
    "\n",
    "\n",
    "bach_df['Bach_Perc'] = bach_df['Bach_Perc'].replace('\\n',\"\",regex=True).str.strip()\n",
    "bach_df = bach_df.iloc[::3, :]\n",
    "bach_df['index'] = np.arange(len(bach_df))\n",
    "# #pop_df['Year'] = str(i)\n",
    "\n",
    "\n",
    "df = pd.merge(\n",
    "        states_df,\n",
    "        bach_df,\n",
    "        how='left',\n",
    "        on=['index']\n",
    ")\n",
    "    \n",
    "df['Year'] = year_str\n",
    "df.tail()\n",
    "\n",
    "# #     for i in list_of_dfs\n",
    "# #     full_df = pd.concat(list_of_dfs, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>index</th>\n",
       "      <th>Bach_Perc</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>1</td>\n",
       "      <td>26.9</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>2</td>\n",
       "      <td>25.5</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>46</td>\n",
       "      <td>39.3</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>47</td>\n",
       "      <td>36.7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>48</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>49</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>50</td>\n",
       "      <td>26.9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>663 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  index Bach_Perc  Year\n",
       "0         Alabama      0      21.1  2006\n",
       "1          Alaska      1      26.9  2006\n",
       "2         Arizona      2      25.5  2006\n",
       "3        Arkansas      3      18.2  2006\n",
       "4      California      4        29  2006\n",
       "..            ...    ...       ...   ...\n",
       "46       Virginia     46      39.3  2018\n",
       "47     Washington     47      36.7  2018\n",
       "48  West Virginia     48      21.3  2018\n",
       "49      Wisconsin     49      30.0  2018\n",
       "50        Wyoming     50      26.9  2018\n",
       "\n",
       "[663 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set up dataframe\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'State':[''], \n",
    "        'Year':[''],\n",
    "        'Bach_Perc':['']\n",
    "    }\n",
    ")\n",
    "\n",
    "list_of_dfs=[]\n",
    "\n",
    "#For each year - run through this process\n",
    "for i in years:\n",
    "    full_link = url+'&od='+str(i)+'-01-01#'\n",
    "    page = requests.get(full_link)\n",
    "    soup = BeautifulSoup(page.text,'lxml')\n",
    "    \n",
    "    \n",
    "    #Grab the state names\n",
    "    states = soup.find_all('span',class_='fred-rls-elm-nm')\n",
    "    states_list = []\n",
    "    for j in states:\n",
    "        state_name = j.text\n",
    "        states_list.append(state_name)\n",
    "\n",
    "    #Package into df\n",
    "    states_df = pd.DataFrame(states_list,columns=['State'])\n",
    "    states_df['index'] = np.arange(len(states_df))\n",
    "    \n",
    "    \n",
    "    #Grab the population values\n",
    "    bachs = soup.find_all('td',class_='fred-rls-elm-vl-td')\n",
    "    bach_list = []\n",
    "    for k in bachs:\n",
    "        bach_num = k.text\n",
    "        bach_list.append(bach_num)\n",
    "\n",
    "\n",
    "    #Package into a df\n",
    "    bach_df = pd.DataFrame(bach_list,columns=['Bach_Perc'])\n",
    "    \n",
    "    #Clean up population values\n",
    "    bach_df['Bach_Perc'] = bach_df['Bach_Perc'].replace('\\n',\"\",regex=True).str.strip()\n",
    "    bach_df['Bach_Perc'] = bach_df['Bach_Perc'].replace(',',\"\",regex=True)\n",
    "    #bach_df = bach_df.apply(pd.to_numeric,errors='ignore')\n",
    "    #Grab every third value\n",
    "    bach_df = bach_df.iloc[::3, :]\n",
    "    #bach_df['Bach_Perc'] = (bach_df['Bach_Perc']*1000).astype(int)\n",
    "    \n",
    "    #Create index for joining\n",
    "    bach_df['index'] = np.arange(len(bach_df))\n",
    "    \n",
    "    #Combine dataframes\n",
    "    full_df = pd.merge(\n",
    "        states_df,\n",
    "        bach_df,\n",
    "        how='left',\n",
    "        on=['index']\n",
    "    )\n",
    "    year_pop = str(i)\n",
    "    full_df['Year'] = year_pop\n",
    "    \n",
    "    \n",
    "    list_of_dfs.append(full_df)\n",
    "    \n",
    "full_df = pd.concat(list_of_dfs)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('states_and_bachs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
